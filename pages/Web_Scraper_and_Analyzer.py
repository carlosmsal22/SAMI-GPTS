import streamlit as st
import pandas as pd
from utils.web_scraper import scrape_reddit, scrape_trustpilot
from utils.gpt_helpers import run_gpt_prompt

def main():
    st.title("ðŸ§  Scrape + Analyze Brand Reputation")

    keyword = st.text_input("Enter a brand (e.g. Secureonix)")
    num = st.slider("How many posts/reviews?", 5, 50, 10)

    if st.button("Scrape the Web"):
        with st.spinner("Scraping data..."):
            reddit_df = scrape_reddit(keyword, max_posts=num)
            trust_df = scrape_trustpilot(keyword, max_reviews=num)
            
            dfs = []
            for df, source in [(reddit_df, "Reddit"), (trust_df, "Trustpilot")]:
                if not df.empty:
                    if 'title' in df.columns:
                        df = df.rename(columns={'title': 'comment'})
                    if 'comment' in df.columns:
                        dfs.append(df)
                    else:
                        st.warning(f"No comments found in {source} data")
            
            if dfs:
                full_df = pd.concat(dfs, ignore_index=True)
                st.session_state.scraped_data = full_df
                st.success(f"Scraped {len(full_df)} comments! Preview:")
                st.dataframe(full_df)
            else:
                st.error("No valid data found from either source")
                st.session_state.scraped_data = None

    if "scraped_data" in st.session_state and st.session_state.scraped_data is not None:
        if st.button("Analyze with GPT"):
            try:
                if 'comment' not in st.session_state.scraped_data.columns:
                    st.error("Data format error: No 'comment' column found")
                    st.write("Available columns:", st.session_state.scraped_data.columns.tolist())
                else:
                    comments = st.session_state.scraped_data['comment'].dropna().head(10)
                    
                    if len(comments) == 0:
                        st.warning("No valid comments found for analysis")
                    else:
                        prompt = (
                            f"Analyze these comments about '{keyword}':\n"
                            "1. Overall sentiment (Positive/Negative/Neutral)\n"
                            "2. Key positive aspects\n"
                            "3. Main complaints\n"
                            "4. Brand reputation summary\n\n"
                            "Comments:\n" + 
                            "\n".join(f"- {c}" for c in comments)
                        )
                        
                        st.markdown("### âœ… Prompt Sent to GPT")
                        st.code(prompt)

                        with st.spinner("Analyzing..."):
                            response = run_gpt_prompt(prompt, module="brand_reputation")
                        
                        st.markdown("### ðŸ§  GPT Response")
                        st.write(response)
                        
            except Exception as e:
                st.error(f"Analysis failed: {str(e)}")
    else:
        st.info("Please scrape data first to enable analysis")

if __name__ == "__main__":
    main()
